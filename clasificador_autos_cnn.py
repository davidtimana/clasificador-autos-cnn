# -*- coding: utf-8 -*-
"""
Clasificador de Autos CNN - Dataset Cars196
Basado en el curso de Visi√≥n por Computador

Este script implementa una Red Neuronal Convolucional (CNN) completa para clasificar
autom√≥viles utilizando el dataset Cars196. Incluye transfer learning, data augmentation,
y t√©cnicas avanzadas de optimizaci√≥n para lograr la mejor precisi√≥n posible.

Caracter√≠sticas principales:
- Transfer Learning con ResNet50V2 pre-entrenado en ImageNet
- Data augmentation para mejorar la generalizaci√≥n
- Fine-tuning autom√°tico de las capas del modelo base
- Callbacks avanzados para optimizaci√≥n del entrenamiento
- Evaluaci√≥n completa con m√∫ltiples m√©tricas

Autor: David Timana
Fecha: 2024
"""

# =============================================================================
# IMPORTACI√ìN DE LIBRER√çAS
# =============================================================================
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.applications import ResNet50V2, VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import cv2
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# =============================================================================
# CONFIGURACI√ìN DE HARDWARE Y GPU
# =============================================================================
# Verificar si hay GPU disponible para acelerar el entrenamiento
print("GPU disponible:", tf.config.list_physical_devices('GPU'))
if tf.config.list_physical_devices('GPU'):
    # Configurar crecimiento de memoria para evitar errores de memoria GPU
    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)
    print("‚úÖ GPU configurada correctamente")
else:
    print("‚ö†Ô∏è  No se detect√≥ GPU, usando CPU (entrenamiento ser√° m√°s lento)")

# =============================================================================
# HIPERPAR√ÅMETROS Y CONFIGURACI√ìN
# =============================================================================
# Par√°metros de imagen y preprocesamiento
IMG_SIZE = 224  # Tama√±o est√°ndar para transfer learning (ResNet, VGG, etc.)
BATCH_SIZE = 32  # Balance entre memoria GPU y estabilidad del entrenamiento
EPOCHS = 50  # N√∫mero m√°ximo de √©pocas (early stopping puede detener antes)
LEARNING_RATE = 0.001  # Learning rate inicial para el optimizador Adam
NUM_CLASSES = 196  # Cars196 tiene exactamente 196 clases de autom√≥viles

# Par√°metros de divisi√≥n de datos
TRAIN_SPLIT = 0.8  # 80% de datos para entrenamiento
VALIDATION_SPLIT = 0.2  # 20% de datos para validaci√≥n

# Par√°metros de regularizaci√≥n
DROPOUT_RATE_CONV = 0.25  # Dropout para capas convolucionales
DROPOUT_RATE_DENSE = 0.5  # Dropout para capas densas (m√°s agresivo)

def cargar_dataset_cars196():
    """
    Carga el dataset Cars196 de TensorFlow Datasets
    
    Esta funci√≥n descarga autom√°ticamente el dataset Cars196 desde TensorFlow Datasets.
    El dataset contiene 16,185 im√°genes de 196 clases diferentes de autom√≥viles,
    divididas en conjuntos de entrenamiento y prueba.
    
    Returns:
        train_dataset: Dataset de TensorFlow para entrenamiento
        test_dataset: Dataset de TensorFlow para prueba
        info: Informaci√≥n del dataset (n√∫mero de ejemplos, clases, etc.)
    """
    print("üîÑ Cargando dataset Cars196 desde TensorFlow Datasets...")
    
    # Cargar dataset con informaci√≥n detallada
    # as_supervised=True: Devuelve tuplas (imagen, etiqueta) en lugar de diccionarios
    dataset, info = tfds.load('cars196', 
                             with_info=True,  # Obtener informaci√≥n del dataset
                             as_supervised=True,  # Formato (imagen, etiqueta)
                             split=['train', 'test'])  # Cargar ambos splits
    
    train_dataset, test_dataset = dataset[0], dataset[1]
    
    # Mostrar informaci√≥n detallada del dataset
    print(f"‚úÖ Dataset Cars196 cargado exitosamente:")
    print(f"   üìä Entrenamiento: {info.splits['train'].num_examples:,} im√°genes")
    print(f"   üìä Prueba: {info.splits['test'].num_examples:,} im√°genes")
    print(f"   üè∑Ô∏è  Clases: {info.features['label'].num_classes} tipos de autom√≥viles")
    print(f"   üìÅ Tama√±o total: ~1.82 GB")
    
    return train_dataset, test_dataset, info

def preprocesar_imagen(image, label):
    """
    Preprocesa las im√°genes para el entrenamiento con data augmentation
    
    Esta funci√≥n aplica transformaciones a las im√°genes para mejorar la generalizaci√≥n
    del modelo. Incluye redimensionamiento, normalizaci√≥n y t√©cnicas de data augmentation
    que ayudan a que el modelo sea m√°s robusto a variaciones en las im√°genes.
    
    Args:
        image: Imagen de entrada (tensor de TensorFlow)
        label: Etiqueta de la imagen
        
    Returns:
        image: Imagen preprocesada y aumentada
        label: Etiqueta sin cambios
    """
    # =============================================================================
    # REDIMENSIONAMIENTO DE IMAGEN
    # =============================================================================
    # Redimensionar todas las im√°genes al tama√±o est√°ndar para transfer learning
    # Esto es necesario porque las im√°genes originales pueden tener diferentes tama√±os
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    
    # =============================================================================
    # NORMALIZACI√ìN DE P√çXELES
    # =============================================================================
    # Convertir a float32 y normalizar valores de p√≠xeles al rango [0, 1]
    # Esto es crucial para el entrenamiento estable de redes neuronales
    image = tf.cast(image, tf.float32) / 255.0
    
    # =============================================================================
    # DATA AUGMENTATION (AUMENTACI√ìN DE DATOS)
    # =============================================================================
    # Estas t√©cnicas crean variaciones de las im√°genes para mejorar la generalizaci√≥n
    
    # 1. FLIP HORIZONTAL (Volteo horizontal)
    # Probabilidad 50% de voltear la imagen horizontalmente
    # √ötil porque los autos pueden aparecer desde diferentes √°ngulos
    if tf.random.uniform([]) > 0.5:
        image = tf.image.random_flip_left_right(image)
    
    # 2. AJUSTE DE BRILLO
    # Probabilidad 50% de ajustar el brillo en ¬±20%
    # Ayuda con diferentes condiciones de iluminaci√≥n
    if tf.random.uniform([]) > 0.5:
        image = tf.image.random_brightness(image, 0.2)
    
    # 3. AJUSTE DE CONTRASTE
    # Probabilidad 50% de ajustar el contraste entre 80% y 120%
    # Mejora la robustez a diferentes condiciones de iluminaci√≥n
    if tf.random.uniform([]) > 0.5:
        image = tf.image.random_contrast(image, 0.8, 1.2)
    
    return image, label

def preprocesar_imagen_test(image, label):
    """
    Preprocesa las im√°genes para validaci√≥n/prueba (sin data augmentation)
    
    Esta funci√≥n aplica solo las transformaciones b√°sicas necesarias para la evaluaci√≥n:
    redimensionamiento y normalizaci√≥n. NO incluye data augmentation porque queremos
    evaluar el modelo con las im√°genes originales para obtener m√©tricas reales.
    
    Args:
        image: Imagen de entrada (tensor de TensorFlow)
        label: Etiqueta de la imagen
        
    Returns:
        image: Imagen preprocesada (sin augmentation)
        label: Etiqueta sin cambios
    """
    # =============================================================================
    # REDIMENSIONAMIENTO DE IMAGEN
    # =============================================================================
    # Redimensionar al mismo tama√±o que las im√°genes de entrenamiento
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    
    # =============================================================================
    # NORMALIZACI√ìN DE P√çXELES
    # =============================================================================
    # Aplicar la misma normalizaci√≥n que en entrenamiento
    # Esto es crucial para mantener consistencia entre entrenamiento y evaluaci√≥n
    image = tf.cast(image, tf.float32) / 255.0
    
    # NOTA: NO aplicamos data augmentation aqu√≠ porque:
    # 1. Queremos evaluar con im√°genes originales
    # 2. Las m√©tricas deben ser consistentes y reproducibles
    # 3. La evaluaci√≥n debe reflejar el rendimiento real del modelo
    
    return image, label

def crear_arquitectura_cnn():
    """
    Crea una arquitectura CNN personalizada optimizada para clasificaci√≥n de autos
    
    Esta funci√≥n construye una red neuronal convolucional desde cero, dise√±ada
    espec√≠ficamente para el dataset Cars196. La arquitectura incluye t√©cnicas
    modernas como Batch Normalization y Dropout para mejorar el entrenamiento
    y prevenir overfitting.
    
    Returns:
        model: Modelo de Keras compilado y listo para entrenar
    """
    print("üèóÔ∏è  Creando arquitectura CNN personalizada...")
    
    # =============================================================================
    # ARQUITECTURA CNN PERSONALIZADA
    # =============================================================================
    # Esta arquitectura est√° dise√±ada espec√≠ficamente para clasificaci√≥n de autos
    # con un balance entre capacidad de aprendizaje y eficiencia computacional
    
    model = models.Sequential([
        # =============================================================================
        # PRIMERA CAPA CONVOLUCIONAL
        # =============================================================================
        # Conv2D(32, (3,3)): 32 filtros de 3x3 p√≠xeles
        # - 32 filtros: Detecta caracter√≠sticas b√°sicas (bordes, texturas)
        # - (3,3): Tama√±o del kernel (receptivo field peque√±o)
        # - activation='relu': Funci√≥n de activaci√≥n no lineal
        # - input_shape: Especifica el tama√±o de entrada (224x224x3)
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        
        # BatchNormalization: Normaliza las activaciones para estabilizar el entrenamiento
        # - Reduce el problema de covariate shift
        # - Permite usar learning rates m√°s altos
        layers.BatchNormalization(),
        
        # MaxPooling2D: Reduce la dimensionalidad espacial
        # - (2,2): Toma el m√°ximo valor en ventanas de 2x2
        # - Reduce el tama√±o de la imagen a la mitad
        layers.MaxPooling2D((2, 2)),
        
        # Dropout: Previene overfitting desactivando aleatoriamente neuronas
        # - 25% de las neuronas se desactivan durante el entrenamiento
        layers.Dropout(DROPOUT_RATE_CONV),
        
        # =============================================================================
        # SEGUNDA CAPA CONVOLUCIONAL
        # =============================================================================
        # 64 filtros: Detecta caracter√≠sticas m√°s complejas
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(DROPOUT_RATE_CONV),
        
        # =============================================================================
        # TERCERA CAPA CONVOLUCIONAL
        # =============================================================================
        # 128 filtros: Detecta caracter√≠sticas de nivel medio
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(DROPOUT_RATE_CONV),
        
        # =============================================================================
        # CUARTA CAPA CONVOLUCIONAL
        # =============================================================================
        # 256 filtros: Detecta caracter√≠sticas de alto nivel
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(DROPOUT_RATE_CONV),
        
        # =============================================================================
        # CAPAS DENSAS (FULLY CONNECTED)
        # =============================================================================
        # Flatten: Convierte el tensor 2D en un vector 1D
        # Necesario para conectar con capas densas
        layers.Flatten(),
        
        # Primera capa densa: 512 neuronas
        # - Procesa las caracter√≠sticas extra√≠das por las capas convolucionales
        # - 512 es un buen balance entre capacidad y eficiencia
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(DROPOUT_RATE_DENSE),  # Dropout m√°s agresivo en capas densas
        
        # Segunda capa densa: 256 neuronas
        # - Reduce la dimensionalidad gradualmente
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(DROPOUT_RATE_DENSE),
        
        # Capa de salida: NUM_CLASSES neuronas (196 para Cars196)
        # - activation='softmax': Convierte salidas en probabilidades
        # - Las probabilidades suman 1.0
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])
    
    print("‚úÖ Arquitectura CNN personalizada creada exitosamente")
    return model

def crear_modelo_transfer_learning():
    """
    Crea un modelo usando transfer learning con ResNet50V2
    
    Esta funci√≥n implementa transfer learning, una t√©cnica poderosa que aprovecha
    el conocimiento aprendido por modelos pre-entrenados en datasets grandes (como ImageNet)
    y lo adapta para nuestro problema espec√≠fico de clasificaci√≥n de autos.
    
    Ventajas del transfer learning:
    - Entrenamiento m√°s r√°pido
    - Mejor generalizaci√≥n
    - Requiere menos datos
    - Mejores resultados finales
    
    Returns:
        model: Modelo completo con ResNet50V2 + capas de clasificaci√≥n
        base_model: Modelo base ResNet50V2 (para fine-tuning posterior)
    """
    print("üöÄ Creando modelo con Transfer Learning (ResNet50V2)...")
    
    # =============================================================================
    # CARGA DEL MODELO BASE PRE-ENTRENADO
    # =============================================================================
    # ResNet50V2: Arquitectura moderna y eficiente
    # - weights='imagenet': Usar pesos pre-entrenados en ImageNet (1.2M im√°genes)
    # - include_top=False: No incluir las capas de clasificaci√≥n finales
    # - input_shape: Especificar el tama√±o de entrada (224x224x3)
    base_model = ResNet50V2(
        weights='imagenet',  # Pesos pre-entrenados en ImageNet
        include_top=False,   # Sin capas de clasificaci√≥n finales
        input_shape=(IMG_SIZE, IMG_SIZE, 3)  # Tama√±o de entrada
    )
    
    # =============================================================================
    # CONGELAR CAPAS DEL MODELO BASE
    # =============================================================================
    # Durante la primera fase del entrenamiento, mantenemos los pesos del modelo base
    # congelados para aprovechar el conocimiento pre-entrenado
    base_model.trainable = False
    print(f"   üîí Capas del modelo base congeladas: {len(base_model.layers)} capas")
    
    # =============================================================================
    # CONSTRUCCI√ìN DEL MODELO COMPLETO
    # =============================================================================
    model = models.Sequential([
        # =============================================================================
        # MODELO BASE (ResNet50V2)
        # =============================================================================
        # Este modelo ya sabe extraer caracter√≠sticas generales de im√°genes
        # (bordes, texturas, formas, etc.) gracias al entrenamiento en ImageNet
        base_model,
        
        # =============================================================================
        # GLOBAL AVERAGE POOLING
        # =============================================================================
        # Convierte el tensor de caracter√≠sticas en un vector
        # - Reduce significativamente el n√∫mero de par√°metros
        # - Mantiene informaci√≥n espacial importante
        # - M√°s eficiente que Flatten() para caracter√≠sticas convolucionales
        layers.GlobalAveragePooling2D(),
        
        # =============================================================================
        # BATCH NORMALIZATION
        # =============================================================================
        # Normaliza las activaciones para estabilizar el entrenamiento
        layers.BatchNormalization(),
        
        # =============================================================================
        # DROPOUT PARA REGULARIZACI√ìN
        # =============================================================================
        # Previene overfitting desactivando 50% de las neuronas
        layers.Dropout(DROPOUT_RATE_DENSE),
        
        # =============================================================================
        # PRIMERA CAPA DENSA
        # =============================================================================
        # 512 neuronas: Procesa las caracter√≠sticas extra√≠das por ResNet50V2
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(DROPOUT_RATE_DENSE),
        
        # =============================================================================
        # SEGUNDA CAPA DENSA
        # =============================================================================
        # 256 neuronas: Reduce dimensionalidad gradualmente
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(DROPOUT_RATE_DENSE),
        
        # =============================================================================
        # CAPA DE SALIDA
        # =============================================================================
        # NUM_CLASSES neuronas (196 para Cars196)
        # Softmax convierte las salidas en probabilidades
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])
    
    print("‚úÖ Modelo de transfer learning creado exitosamente")
    print(f"   üìä Par√°metros totales: {model.count_params():,}")
    print(f"   üîí Par√°metros congelados: {sum([tf.size(w).numpy() for w in base_model.weights]):,}")
    print(f"   üîì Par√°metros entrenables: {model.count_params() - sum([tf.size(w).numpy() for w in base_model.weights]):,}")
    
    return model, base_model

def compilar_y_entrenar_modelo(model, train_dataset, val_dataset, use_transfer_learning=False):
    """
    Compila y entrena el modelo
    """
    print("Compilando modelo...")
    
    # Optimizador
    optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)
    
    # Compilar modelo
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy', 'top_5_accuracy']
    )
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        ),
        ModelCheckpoint(
            'mejor_modelo_autos.h5',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    print("Iniciando entrenamiento...")
    
    # Entrenamiento inicial
    history = model.fit(
        train_dataset,
        validation_data=val_dataset,
        epochs=EPOCHS,
        callbacks=callbacks,
        verbose=1
    )
    
    # Si es transfer learning, hacer fine-tuning
    if use_transfer_learning:
        print("Iniciando fine-tuning...")
        
        # Descongelar algunas capas del modelo base
        base_model = model.layers[0]
        base_model.trainable = True
        
        # Congelar las primeras capas
        for layer in base_model.layers[:-30]:
            layer.trainable = False
        
        # Recompilar con learning rate m√°s bajo
        model.compile(
            optimizer=optimizers.Adam(learning_rate=LEARNING_RATE/10),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', 'top_5_accuracy']
        )
        
        # Fine-tuning
        history_fine = model.fit(
            train_dataset,
            validation_data=val_dataset,
            epochs=20,
            callbacks=callbacks,
            verbose=1
        )
        
        # Combinar historiales
        for key in history.history:
            history.history[key].extend(history_fine.history[key])
    
    return history

def evaluar_modelo(model, test_dataset, info):
    """
    Eval√∫a el modelo en el conjunto de prueba
    """
    print("Evaluando modelo...")
    
    # Evaluaci√≥n
    test_loss, test_accuracy, test_top5_accuracy = model.evaluate(test_dataset, verbose=1)
    
    print(f"\nResultados de evaluaci√≥n:")
    print(f"P√©rdida de prueba: {test_loss:.4f}")
    print(f"Precisi√≥n de prueba: {test_accuracy:.4f}")
    print(f"Top-5 precisi√≥n: {test_top5_accuracy:.4f}")
    
    # Predicciones para an√°lisis detallado
    predictions = []
    true_labels = []
    
    for images, labels in test_dataset.take(100):  # Evaluar en 100 ejemplos
        pred = model.predict(images, verbose=0)
        predictions.extend(np.argmax(pred, axis=1))
        true_labels.extend(labels.numpy())
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(true_labels, predictions)
    
    # Visualizar matriz de confusi√≥n
    plt.figure(figsize=(12, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matriz de Confusi√≥n')
    plt.ylabel('Etiqueta Real')
    plt.xlabel('Etiqueta Predicha')
    plt.show()
    
    return test_accuracy, test_top5_accuracy

def visualizar_resultados(history):
    """
    Visualiza los resultados del entrenamiento
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Precisi√≥n
    axes[0, 0].plot(history.history['accuracy'], label='Entrenamiento')
    axes[0, 0].plot(history.history['val_accuracy'], label='Validaci√≥n')
    axes[0, 0].set_title('Precisi√≥n del Modelo')
    axes[0, 0].set_xlabel('√âpoca')
    axes[0, 0].set_ylabel('Precisi√≥n')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # P√©rdida
    axes[0, 1].plot(history.history['loss'], label='Entrenamiento')
    axes[0, 1].plot(history.history['val_loss'], label='Validaci√≥n')
    axes[0, 1].set_title('P√©rdida del Modelo')
    axes[0, 1].set_xlabel('√âpoca')
    axes[0, 1].set_ylabel('P√©rdida')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # Top-5 Precisi√≥n
    axes[1, 0].plot(history.history['top_5_accuracy'], label='Entrenamiento')
    axes[1, 0].plot(history.history['val_top_5_accuracy'], label='Validaci√≥n')
    axes[1, 0].set_title('Top-5 Precisi√≥n del Modelo')
    axes[1, 0].set_xlabel('√âpoca')
    axes[1, 0].set_ylabel('Top-5 Precisi√≥n')
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    
    # Learning Rate
    if 'lr' in history.history:
        axes[1, 1].plot(history.history['lr'])
        axes[1, 1].set_title('Learning Rate')
        axes[1, 1].set_xlabel('√âpoca')
        axes[1, 1].set_ylabel('Learning Rate')
        axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.show()

def predecir_imagen_personalizada(model, ruta_imagen):
    """
    Predice la clase de una imagen personalizada
    """
    # Cargar y preprocesar imagen
    img = tf.keras.preprocessing.image.load_img(ruta_imagen, target_size=(IMG_SIZE, IMG_SIZE))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = img_array / 255.0
    img_array = tf.expand_dims(img_array, 0)
    
    # Predicci√≥n
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    confidence = np.max(predictions[0])
    
    # Top-5 predicciones
    top_5_indices = np.argsort(predictions[0])[-5:][::-1]
    top_5_confidences = predictions[0][top_5_indices]
    
    return predicted_class, confidence, top_5_indices, top_5_confidences

def main():
    """
    Funci√≥n principal
    """
    print("=== CLASIFICADOR DE AUTOS CNN - DATASET CARS196 ===")
    print("Basado en el curso de Visi√≥n por Computador\n")
    
    # 1. Cargar dataset
    train_dataset, test_dataset, info = cargar_dataset_cars196()
    
    # 2. Preprocesar datos
    print("Preprocesando datos...")
    
    # Aplicar preprocesamiento
    train_dataset = train_dataset.map(preprocesar_imagen, num_parallel_calls=tf.data.AUTOTUNE)
    test_dataset = test_dataset.map(preprocesar_imagen_test, num_parallel_calls=tf.data.AUTOTUNE)
    
    # Configurar para rendimiento
    train_dataset = train_dataset.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    
    # Dividir train en train y validation
    train_size = int(0.8 * info.splits['train'].num_examples)
    val_size = info.splits['train'].num_examples - train_size
    
    train_dataset_final = train_dataset.take(train_size // BATCH_SIZE)
    val_dataset = train_dataset.skip(train_size // BATCH_SIZE).take(val_size // BATCH_SIZE)
    
    # 3. Crear modelo
    print("\nSeleccionando arquitectura...")
    print("1. Arquitectura personalizada (m√°s r√°pida)")
    print("2. Transfer Learning con ResNet50V2 (mejor precisi√≥n)")
    
    # Por defecto usar transfer learning para mejor rendimiento
    use_transfer_learning = True
    
    if use_transfer_learning:
        model, base_model = crear_modelo_transfer_learning()
    else:
        model = crear_arquitectura_cnn()
    
    # Mostrar resumen del modelo
    model.summary()
    
    # 4. Entrenar modelo
    history = compilar_y_entrenar_modelo(
        model, 
        train_dataset_final, 
        val_dataset, 
        use_transfer_learning=use_transfer_learning
    )
    
    # 5. Evaluar modelo
    test_accuracy, test_top5_accuracy = evaluar_modelo(model, test_dataset, info)
    
    # 6. Visualizar resultados
    visualizar_resultados(history)
    
    # 7. Guardar modelo
    model.save('modelo_autos_final.h5')
    print("\nModelo guardado como 'modelo_autos_final.h5'")
    
    print(f"\n=== RESUMEN FINAL ===")
    print(f"Precisi√≥n final: {test_accuracy:.4f}")
    print(f"Top-5 precisi√≥n: {test_top5_accuracy:.4f}")
    print(f"Modelo listo para usar con im√°genes personalizadas!")
    
    return model, history

if __name__ == "__main__":
    # Ejecutar entrenamiento
    modelo_entrenado, historial = main()
    
    # Ejemplo de uso con imagen personalizada
    print("\n=== EJEMPLO DE USO CON IMAGEN PERSONALIZADA ===")
    print("Para usar el modelo con tus 100 im√°genes personalizadas:")
    print("1. Coloca las im√°genes en una carpeta")
    print("2. Usa la funci√≥n predecir_imagen_personalizada()")
    print("3. Ejemplo:")
    print("   ruta_imagen = 'tu_imagen.jpg'")
    print("   clase_predicha, confianza, top5_indices, top5_confianzas = predecir_imagen_personalizada(modelo_entrenado, ruta_imagen)")
