{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generative Adversarial Network (GAN) para Generaci√≥n de Im√°genes de Autom√≥viles\n",
    "VERSI√ìN OPTIMIZADA PARA GOOGLE COLAB\n",
    "\n",
    "Este script implementa una Deep Convolutional Generative Adversarial Network (DCGAN)\n",
    "para generar im√°genes de autom√≥viles utilizando el dataset CIFAR-10. Incluye:\n",
    "- Carga y preparaci√≥n del dataset CIFAR-10 (filtrado para autom√≥viles)\n",
    "- Implementaci√≥n de arquitecturas Generator y Discriminator\n",
    "- Entrenamiento adversarial con optimizaci√≥n de hiperpar√°metros\n",
    "- Generaci√≥n de im√°genes sint√©ticas de alta calidad\n",
    "- Visualizaci√≥n de resultados y progreso del entrenamiento\n",
    "\n",
    "Autor: David Timana\n",
    "Fecha: 2024\n",
    "Curso: Visi√≥n por Computador - GANs\n",
    "Versi√≥n: Google Colab Optimizada\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732eb75",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 1: IMPORTAR LAS BIBLIOTECAS NECESARIAS\n",
    "# =============================================================================\n",
    "\n",
    "# Verificar si estamos en Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üöÄ Detectado Google Colab - Configurando entorno...\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Ejecutando en entorno local\")\n",
    "\n",
    "# Importar bibliotecas principales de PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Importar bibliotecas para an√°lisis de datos y manipulaci√≥n\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importar bibliotecas para manejo de advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraciones espec√≠ficas para Colab\n",
    "if IN_COLAB:\n",
    "    # Montar Google Drive (opcional)\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"üìÅ Google Drive montado exitosamente\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è No se pudo montar Google Drive - continuando sin √©l\")\n",
    "    \n",
    "    # Configurar matplotlib para Colab\n",
    "    plt.rcParams['figure.figsize'] = [12, 8]\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1923f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 2: CONFIGURACI√ìN DEL PROYECTO Y HIPERPAR√ÅMETROS\n",
    "# =============================================================================\n",
    "\n",
    "def configurar_proyecto():\n",
    "    \"\"\"\n",
    "    Configura los hiperpar√°metros y par√°metros del proyecto.\n",
    "    Optimizado para Google Colab con detecci√≥n autom√°tica de GPU.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con la configuraci√≥n del proyecto\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASO 2: CONFIGURACI√ìN DEL PROYECTO Y HIPERPAR√ÅMETROS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Configuraci√≥n principal del proyecto\n",
    "    CONFIG = {\n",
    "        \"batch_size\": 64,           # Tama√±o del lote para entrenamiento\n",
    "        \"latent_dim\": 100,          # Dimensi√≥n del espacio latente (vector de ruido)\n",
    "        \"lr\": 0.0002,              # Tasa de aprendizaje (est√°ndar para GANs)\n",
    "        \"beta1\": 0.5,              # Par√°metro beta1 para optimizador Adam\n",
    "        \"epochs\": 50,              # N√∫mero de √©pocas de entrenamiento\n",
    "        \"num_final_images\": 30,    # N√∫mero de im√°genes finales a generar\n",
    "        \"image_size\": 64,          # Tama√±o de imagen de salida (64x64 p√≠xeles)\n",
    "        \"channels\": 3              # N√∫mero de canales de color (RGB)\n",
    "    }\n",
    "    \n",
    "    # Configuraciones espec√≠ficas para Colab\n",
    "    if IN_COLAB:\n",
    "        CONFIG[\"batch_size\"] = 128  # Lotes m√°s grandes en Colab con GPU\n",
    "        CONFIG[\"epochs\"] = 30       # Menos √©pocas para demostraci√≥n\n",
    "    \n",
    "    # Crear directorios para los resultados\n",
    "    if IN_COLAB:\n",
    "        os.makedirs(\"/content/results/final_generated\", exist_ok=True)\n",
    "        CONFIG[\"results_path\"] = \"/content/results/final_generated\"\n",
    "    else:\n",
    "        os.makedirs(\"results/final_generated\", exist_ok=True)\n",
    "        CONFIG[\"results_path\"] = \"results/final_generated\"\n",
    "    \n",
    "    # Mostrar configuraci√≥n\n",
    "    print(\"=== CONFIGURACI√ìN DEL PROYECTO ===\")\n",
    "    for key, value in CONFIG.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Directorios creados: {CONFIG['results_path']}\")\n",
    "    \n",
    "    return CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753a48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 3: FUNCI√ìN PARA REPRODUCIBILIDAD\n",
    "# =============================================================================\n",
    "\n",
    "def establecer_reproducibilidad(seed=42):\n",
    "    \"\"\"\n",
    "    Establece las semillas para garantizar reproducibilidad de resultados.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): Semilla para la generaci√≥n de n√∫meros aleatorios\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASO 3: ESTABLECER REPRODUCIBILIDAD\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Establecer semillas para PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Establecer semillas para NumPy y Random\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Configuraciones adicionales de PyTorch para reproducibilidad\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(f\"‚úì Reproducibilidad establecida con semilla: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a17fa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 4: PREPARACI√ìN DEL DATASET\n",
    "# =============================================================================\n",
    "\n",
    "class CarDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado que filtra solo los autom√≥viles del dataset CIFAR-10.\n",
    "    \n",
    "    Esta clase crea un dataset espec√≠fico para autom√≥viles, que corresponde\n",
    "    a la clase 1 en el dataset CIFAR-10 original.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transform=None):\n",
    "        \"\"\"\n",
    "        Inicializa el dataset de autom√≥viles.\n",
    "        \n",
    "        Args:\n",
    "            transform: Transformaciones a aplicar a las im√°genes\n",
    "        \"\"\"\n",
    "        # Cargar el dataset CIFAR-10 completo\n",
    "        cifar_dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', \n",
    "            train=True, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "        \n",
    "        # Filtrar solo los autom√≥viles (etiqueta 1 en CIFAR-10)\n",
    "        self.car_indices = [i for i, (_, label) in enumerate(cifar_dataset) if label == 1]\n",
    "        self.cifar_dataset = cifar_dataset\n",
    "        \n",
    "        print(f\"üöó Encontrados {len(self.car_indices)} autom√≥viles en el dataset CIFAR-10.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Retorna el n√∫mero total de autom√≥viles en el dataset.\"\"\"\n",
    "        return len(self.car_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Obtiene una imagen de autom√≥vil por su √≠ndice.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): √çndice de la imagen\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Imagen de autom√≥vil\n",
    "        \"\"\"\n",
    "        img, _ = self.cifar_dataset[self.car_indices[idx]]\n",
    "        return img\n",
    "\n",
    "def preparar_dataset(CONFIG):\n",
    "    \"\"\"\n",
    "    Prepara el dataset de autom√≥viles para el entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        CONFIG (dict): Configuraci√≥n del proyecto\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (dataloader, dataset)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASO 4: PREPARACI√ìN DEL DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Definir las transformaciones para las im√°genes\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(CONFIG[\"image_size\"]),                    # Redimensionar a 64x64\n",
    "        transforms.ToTensor(),                                      # Convertir a tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),    # Normalizar a [-1, 1]\n",
    "    ])\n",
    "    \n",
    "    # Crear el dataset de autom√≥viles\n",
    "    dataset = CarDataset(transform=transform)\n",
    "    \n",
    "    # Crear el DataLoader con configuraci√≥n optimizada para Colab\n",
    "    num_workers = 2 if IN_COLAB else 0\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=CONFIG[\"batch_size\"], \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    print(\"=== INFORMACI√ìN DEL DATASET ===\")\n",
    "    print(f\"Tama√±o del dataset: {len(dataset)} im√°genes\")\n",
    "    print(f\"Tama√±o del lote: {CONFIG['batch_size']}\")\n",
    "    print(f\"N√∫mero de lotes por √©poca: {len(dataloader)}\")\n",
    "    print(f\"Resoluci√≥n de imagen: {CONFIG['image_size']}x{CONFIG['image_size']}\")\n",
    "    print(f\"Canales de color: {CONFIG['channels']} (RGB)\")\n",
    "    print(f\"Workers: {num_workers}\")\n",
    "    print(f\"Pin Memory: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    return dataloader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531ed68",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 5: FUNCI√ìN DE INICIALIZACI√ìN DE PESOS\n",
    "# =============================================================================\n",
    "\n",
    "def inicializar_pesos(m):\n",
    "    \"\"\"\n",
    "    Inicializa los pesos de las capas convolucionales y de normalizaci√≥n.\n",
    "    \n",
    "    Esta funci√≥n aplica una inicializaci√≥n espec√≠fica para GANs que ayuda\n",
    "    a estabilizar el entrenamiento adversarial.\n",
    "    \n",
    "    Args:\n",
    "        m: M√≥dulo de PyTorch (capa de la red)\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    # Inicializaci√≥n para capas convolucionales\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    \n",
    "    # Inicializaci√≥n para capas de normalizaci√≥n por lotes\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d0cfe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 6: ARQUITECTURA DEL GENERADOR\n",
    "# =============================================================================\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generador: Transforma un vector de ruido latente en una imagen realista.\n",
    "    \n",
    "    La arquitectura utiliza capas de convoluci√≥n transpuesta (ConvTranspose2d)\n",
    "    para realizar un proceso de \"upsampling\" progresivo, transformando un\n",
    "    vector de ruido de 100 dimensiones en una imagen de 64x64 p√≠xeles.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, channels):\n",
    "        \"\"\"\n",
    "        Inicializa la arquitectura del generador.\n",
    "        \n",
    "        Args:\n",
    "            latent_dim (int): Dimensi√≥n del espacio latente\n",
    "            channels (int): N√∫mero de canales de salida (RGB)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Capa 1: Vector latente -> (512, 4, 4)\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Capa 2: (512, 4, 4) -> (256, 8, 8)\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Capa 3: (256, 8, 8) -> (128, 16, 16)\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Capa 4: (128, 16, 16) -> (64, 32, 32)\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Capa 5: (64, 32, 32) -> (channels, 64, 64)\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()  # Normaliza la salida a [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass del generador.\n",
    "        \n",
    "        Args:\n",
    "            input (torch.Tensor): Vector de ruido latente\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Imagen generada\n",
    "        \"\"\"\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e6782",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 7: ARQUITECTURA DEL DISCRIMINADOR\n",
    "# =============================================================================\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminador: Clasifica im√°genes como reales o generadas.\n",
    "    \n",
    "    La arquitectura utiliza capas convolucionales para reducir progresivamente\n",
    "    la resoluci√≥n de la imagen hasta obtener una √∫nica probabilidad que\n",
    "    indica si la imagen es real (1) o generada (0).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Inicializa la arquitectura del discriminador.\n",
    "        \n",
    "        Args:\n",
    "            channels (int): N√∫mero de canales de entrada (RGB)\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Capa 1: (channels, 64, 64) -> (64, 32, 32)\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Capa 2: (64, 32, 32) -> (128, 16, 16)\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Capa 3: (128, 16, 16) -> (256, 8, 8)\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Capa 4: (256, 8, 8) -> (512, 4, 4)\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Capa 5: (512, 4, 4) -> (1, 1, 1) - Probabilidad final\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()  # Produce una probabilidad entre 0 y 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass del discriminador.\n",
    "        \n",
    "        Args:\n",
    "            input (torch.Tensor): Imagen de entrada\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Probabilidad de que la imagen sea real\n",
    "        \"\"\"\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8a295",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 8: FUNCIONES AUXILIARES PARA VISUALIZACI√ìN Y M√âTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "def calcular_metricas_gan(generator, discriminator, dataloader, device, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas de calidad para evaluar el rendimiento de la GAN.\n",
    "    \n",
    "    Args:\n",
    "        generator: Modelo generador\n",
    "        discriminator: Modelo discriminador\n",
    "        dataloader: DataLoader con im√°genes reales\n",
    "        device: Dispositivo de c√≥mputo\n",
    "        num_samples: N√∫mero de muestras para calcular m√©tricas\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con las m√©tricas calculadas\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Calculando m√©tricas de calidad de la GAN...\")\n",
    "    \n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # M√©tricas del discriminador\n",
    "        real_confidences = []\n",
    "        fake_confidences = []\n",
    "        \n",
    "        # Recolectar confianzas del discriminador\n",
    "        for i, real_data in enumerate(dataloader):\n",
    "            if i * dataloader.batch_size >= num_samples:\n",
    "                break\n",
    "                \n",
    "            real_data = real_data.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "            \n",
    "            # Confianza en im√°genes reales\n",
    "            real_conf = discriminator(real_data).cpu().numpy()\n",
    "            real_confidences.extend(real_conf.flatten())\n",
    "            \n",
    "            # Confianza en im√°genes generadas\n",
    "            noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "            fake_data = generator(noise)\n",
    "            fake_conf = discriminator(fake_data).cpu().numpy()\n",
    "            fake_confidences.extend(fake_conf.flatten())\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        real_confidences = np.array(real_confidences[:num_samples])\n",
    "        fake_confidences = np.array(fake_confidences[:num_samples])\n",
    "        \n",
    "        # M√©tricas de confianza\n",
    "        avg_real_conf = np.mean(real_confidences)\n",
    "        avg_fake_conf = np.mean(fake_confidences)\n",
    "        std_real_conf = np.std(real_confidences)\n",
    "        std_fake_conf = np.std(fake_confidences)\n",
    "        \n",
    "        # M√©trica de separabilidad (cu√°n bien distingue el discriminador)\n",
    "        separability = avg_real_conf - avg_fake_conf\n",
    "        \n",
    "        # M√©trica de estabilidad (varianza de las confianzas)\n",
    "        stability = (std_real_conf + std_fake_conf) / 2\n",
    "        \n",
    "        # M√©trica de balance (cu√°n equilibradas est√°n las confianzas)\n",
    "        balance = 1 - abs(avg_real_conf - (1 - avg_fake_conf))\n",
    "        \n",
    "        # M√©trica de calidad general\n",
    "        quality_score = (separability * 0.4 + (1 - stability) * 0.3 + balance * 0.3)\n",
    "        \n",
    "        metricas = {\n",
    "            'avg_real_confidence': avg_real_conf,\n",
    "            'avg_fake_confidence': avg_fake_conf,\n",
    "            'std_real_confidence': std_real_conf,\n",
    "            'std_fake_confidence': std_fake_conf,\n",
    "            'separability': separability,\n",
    "            'stability': stability,\n",
    "            'balance': balance,\n",
    "            'quality_score': quality_score\n",
    "        }\n",
    "        \n",
    "        print(\"=== M√âTRICAS DE CALIDAD ===\")\n",
    "        print(f\"Confianza promedio en im√°genes reales: {avg_real_conf:.4f}\")\n",
    "        print(f\"Confianza promedio en im√°genes generadas: {avg_fake_conf:.4f}\")\n",
    "        print(f\"Separabilidad (real - fake): {separability:.4f}\")\n",
    "        print(f\"Estabilidad (menor = mejor): {stability:.4f}\")\n",
    "        print(f\"Balance: {balance:.4f}\")\n",
    "        print(f\"Puntuaci√≥n de calidad general: {quality_score:.4f}\")\n",
    "        \n",
    "        return metricas\n",
    "\n",
    "def guardar_metricas(metricas, epoch, results_path):\n",
    "    \"\"\"\n",
    "    Guarda las m√©tricas en un archivo CSV para seguimiento.\n",
    "    \n",
    "    Args:\n",
    "        metricas (dict): Diccionario con las m√©tricas\n",
    "        epoch (int): N√∫mero de √©poca\n",
    "        results_path (str): Ruta para guardar las m√©tricas\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    import os\n",
    "    \n",
    "    csv_path = os.path.join(results_path, \"metricas_gan.csv\")\n",
    "    \n",
    "    # Crear archivo si no existe\n",
    "    if not os.path.exists(csv_path):\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['epoch'] + list(metricas.keys()))\n",
    "    \n",
    "    # Agregar m√©tricas de la √©poca actual\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch] + list(metricas.values()))\n",
    "\n",
    "def guardar_imagenes_progreso(generator, fixed_noise, epoch, device, results_path):\n",
    "    \"\"\"\n",
    "    Guarda una grilla de im√°genes para visualizar el progreso del entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        generator: Modelo generador\n",
    "        fixed_noise: Ruido fijo para visualizaci√≥n consistente\n",
    "        epoch (int): N√∫mero de √©poca actual\n",
    "        device: Dispositivo de c√≥mputo (CPU/GPU)\n",
    "        results_path: Ruta para guardar las im√°genes\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(fixed_noise).detach().cpu()\n",
    "    \n",
    "    # Crear grilla de im√°genes\n",
    "    grid = torchvision.utils.make_grid(fake_images, padding=2, normalize=True)\n",
    "    \n",
    "    # Visualizar y guardar\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    plt.title(f\"Im√°genes Generadas - √âpoca {epoch}\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Guardar imagen\n",
    "    save_path = os.path.join(results_path, f\"progress_epoch_{epoch:03d}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # Mostrar en Colab si es necesario\n",
    "    if IN_COLAB and epoch % 10 == 0:  # Mostrar cada 10 √©pocas\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "        plt.title(f\"Progreso - √âpoca {epoch}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    \n",
    "    generator.train()\n",
    "\n",
    "def generar_imagenes_finales(generator, latent_dim, num_images, device, results_path):\n",
    "    \"\"\"\n",
    "    Genera y guarda el conjunto final de im√°genes sint√©ticas.\n",
    "    \n",
    "    Args:\n",
    "        generator: Modelo generador entrenado\n",
    "        latent_dim (int): Dimensi√≥n del espacio latente\n",
    "        num_images (int): N√∫mero de im√°genes a generar\n",
    "        device: Dispositivo de c√≥mputo (CPU/GPU)\n",
    "        results_path: Ruta para guardar las im√°genes\n",
    "    \"\"\"\n",
    "    print(f\"\\nüé® Generando las {num_images} im√°genes finales...\")\n",
    "    \n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generar ruido aleatorio\n",
    "        noise = torch.randn(num_images, latent_dim, 1, 1, device=device)\n",
    "        \n",
    "        # Generar im√°genes\n",
    "        final_images = generator(noise).detach().cpu()\n",
    "\n",
    "    # Guardar cada imagen individualmente\n",
    "    for i in range(num_images):\n",
    "        img = final_images[i]\n",
    "        save_path = os.path.join(results_path, f\"car_{i+1:02d}.png\")\n",
    "        torchvision.utils.save_image(img, save_path, normalize=True)\n",
    "\n",
    "    # Guardar la grilla final\n",
    "    grid = torchvision.utils.make_grid(\n",
    "        final_images, \n",
    "        nrow=6, \n",
    "        padding=2, \n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # Mostrar y guardar la grilla final\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    plt.title(f\"{num_images} Autom√≥viles Generados por la GAN (Final)\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Guardar grilla\n",
    "    grid_path = os.path.join(results_path, \"final_30_cars_grid.png\")\n",
    "    plt.savefig(grid_path, bbox_inches='tight', dpi=150)\n",
    "    \n",
    "    # Mostrar en Colab\n",
    "    if IN_COLAB:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"‚úÖ {num_images} im√°genes guardadas en '{results_path}'.\")\n",
    "\n",
    "def visualizar_metricas(results_path):\n",
    "    \"\"\"\n",
    "    Visualiza las m√©tricas guardadas durante el entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        results_path (str): Ruta donde est√°n guardadas las m√©tricas\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    csv_path = os.path.join(results_path, \"metricas_gan.csv\")\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"‚ö†Ô∏è No se encontraron m√©tricas para visualizar.\")\n",
    "        return\n",
    "    \n",
    "    # Cargar m√©tricas\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('M√©tricas de Calidad de la GAN durante el Entrenamiento', fontsize=16)\n",
    "    \n",
    "    # Gr√°fico 1: Confianzas del discriminador\n",
    "    axes[0, 0].plot(df['epoch'], df['avg_real_confidence'], 'b-', label='Im√°genes Reales', linewidth=2)\n",
    "    axes[0, 0].plot(df['epoch'], df['avg_fake_confidence'], 'r-', label='Im√°genes Generadas', linewidth=2)\n",
    "    axes[0, 0].set_title('Confianza del Discriminador')\n",
    "    axes[0, 0].set_xlabel('√âpoca')\n",
    "    axes[0, 0].set_ylabel('Confianza Promedio')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 2: Separabilidad\n",
    "    axes[0, 1].plot(df['epoch'], df['separability'], 'g-', linewidth=2)\n",
    "    axes[0, 1].set_title('Separabilidad (Real - Fake)')\n",
    "    axes[0, 1].set_xlabel('√âpoca')\n",
    "    axes[0, 1].set_ylabel('Separabilidad')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 3: Estabilidad\n",
    "    axes[1, 0].plot(df['epoch'], df['stability'], 'orange', linewidth=2)\n",
    "    axes[1, 0].set_title('Estabilidad (Menor = Mejor)')\n",
    "    axes[1, 0].set_xlabel('√âpoca')\n",
    "    axes[1, 0].set_ylabel('Estabilidad')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 4: Puntuaci√≥n de Calidad General\n",
    "    axes[1, 1].plot(df['epoch'], df['quality_score'], 'purple', linewidth=2)\n",
    "    axes[1, 1].set_title('Puntuaci√≥n de Calidad General')\n",
    "    axes[1, 1].set_xlabel('√âpoca')\n",
    "    axes[1, 1].set_ylabel('Puntuaci√≥n')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar gr√°fico\n",
    "    save_path = os.path.join(results_path, \"metricas_evolucion.png\")\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"üìä Gr√°fico de m√©tricas guardado en: {save_path}\")\n",
    "    \n",
    "    # Mostrar resumen de m√©tricas finales\n",
    "    ultima_fila = df.iloc[-1]\n",
    "    print(\"\\n=== RESUMEN DE M√âTRICAS FINALES ===\")\n",
    "    print(f\"Confianza en im√°genes reales: {ultima_fila['avg_real_confidence']:.4f}\")\n",
    "    print(f\"Confianza en im√°genes generadas: {ultima_fila['avg_fake_confidence']:.4f}\")\n",
    "    print(f\"Separabilidad: {ultima_fila['separability']:.4f}\")\n",
    "    print(f\"Estabilidad: {ultima_fila['stability']:.4f}\")\n",
    "    print(f\"Balance: {ultima_fila['balance']:.4f}\")\n",
    "    print(f\"Puntuaci√≥n de calidad general: {ultima_fila['quality_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a238c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 9: BUCLE PRINCIPAL DE ENTRENAMIENTO\n",
    "# =============================================================================\n",
    "\n",
    "def entrenar_gan(CONFIG):\n",
    "    \"\"\"\n",
    "    Funci√≥n principal que orquesta todo el proceso de entrenamiento de la GAN.\n",
    "    \n",
    "    Args:\n",
    "        CONFIG (dict): Configuraci√≥n del proyecto\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASO 9: BUCLE PRINCIPAL DE ENTRENAMIENTO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"üöÄ Iniciando el entrenamiento de la GAN Definitiva...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- Configuraci√≥n inicial ---\n",
    "    establecer_reproducibilidad(42)\n",
    "    \n",
    "    # Detectar dispositivo (optimizado para Colab)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"‚úÖ Dispositivo de entrenamiento: {device}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üöÄ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "    # --- Preparaci√≥n del dataset ---\n",
    "    dataloader, dataset = preparar_dataset(CONFIG)\n",
    "\n",
    "    # --- Inicializaci√≥n de modelos ---\n",
    "    print(\"\\n=== INICIALIZACI√ìN DE MODELOS ===\")\n",
    "    netG = Generator(CONFIG[\"latent_dim\"], CONFIG[\"channels\"]).to(device)\n",
    "    netD = Discriminator(CONFIG[\"channels\"]).to(device)\n",
    "    \n",
    "    # Aplicar inicializaci√≥n de pesos\n",
    "    netG.apply(inicializar_pesos)\n",
    "    netD.apply(inicializar_pesos)\n",
    "    print(\"‚úÖ Modelos Generador y Discriminador inicializados.\")\n",
    "\n",
    "    # --- Configuraci√≥n de optimizadores y funci√≥n de p√©rdida ---\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    optimizerD = optim.Adam(\n",
    "        netD.parameters(), \n",
    "        lr=CONFIG[\"lr\"], \n",
    "        betas=(CONFIG[\"beta1\"], 0.999)\n",
    "    )\n",
    "    optimizerG = optim.Adam(\n",
    "        netG.parameters(), \n",
    "        lr=CONFIG[\"lr\"], \n",
    "        betas=(CONFIG[\"beta1\"], 0.999)\n",
    "    )\n",
    "\n",
    "    # --- Ruido fijo para visualizaci√≥n consistente ---\n",
    "    fixed_noise = torch.randn(64, CONFIG[\"latent_dim\"], 1, 1, device=device)\n",
    "\n",
    "    # --- Etiquetas para la funci√≥n de p√©rdida ---\n",
    "    real_label = 1.\n",
    "    fake_label = 0.\n",
    "\n",
    "    # --- Bucle principal de entrenamiento ---\n",
    "    print(f\"\\nüéØ Comenzando entrenamiento por {CONFIG['epochs']} √©pocas...\")\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "\n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        progress_bar = tqdm(dataloader, desc=f\"√âpoca {epoch+1}/{CONFIG['epochs']}\")\n",
    "        \n",
    "        for i, data in enumerate(progress_bar):\n",
    "            # ---------------------------\n",
    "            # (1) ACTUALIZAR RED DISCRIMINADOR\n",
    "            # Maximizar log(D(x)) + log(1 - D(G(z)))\n",
    "            # ---------------------------\n",
    "            \n",
    "            ## Entrenar con im√°genes reales\n",
    "            netD.zero_grad()\n",
    "            real_cpu = data.to(device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "            output = netD(real_cpu).view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            ## Entrenar con im√°genes falsas\n",
    "            noise = torch.randn(b_size, CONFIG[\"latent_dim\"], 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            label.fill_(fake_label)\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "            # ---------------------------\n",
    "            # (2) ACTUALIZAR RED GENERADOR\n",
    "            # Maximizar log(D(G(z)))\n",
    "            # ---------------------------\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # Las etiquetas falsas son reales para el costo del generador\n",
    "            output = netD(fake).view(-1)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "\n",
    "            # --- Guardar p√©rdidas y actualizar barra de progreso ---\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss_D': f'{errD.item():.4f}',\n",
    "                'Loss_G': f'{errG.item():.4f}',\n",
    "                'D(x)': f'{D_x:.4f}',\n",
    "                'D(G(z))': f'{D_G_z1:.4f}/{D_G_z2:.4f}'\n",
    "            })\n",
    "\n",
    "        # --- Calcular y guardar m√©tricas cada 5 √©pocas ---\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            metricas = calcular_metricas_gan(netG, netD, dataloader, device, num_samples=500)\n",
    "            guardar_metricas(metricas, epoch + 1, CONFIG[\"results_path\"])\n",
    "        \n",
    "        # --- Guardar im√°genes de progreso al final de cada √©poca ---\n",
    "        guardar_imagenes_progreso(netG, fixed_noise, epoch + 1, device, CONFIG[\"results_path\"])\n",
    "\n",
    "    print(\"üèÅ Entrenamiento completado.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- Calcular m√©tricas finales ---\n",
    "    print(\"\\nüìä Calculando m√©tricas finales...\")\n",
    "    metricas_finales = calcular_metricas_gan(netG, netD, dataloader, device, num_samples=1000)\n",
    "    guardar_metricas(metricas_finales, CONFIG[\"epochs\"], CONFIG[\"results_path\"])\n",
    "    \n",
    "    # --- Generaci√≥n final de im√°genes ---\n",
    "    generar_imagenes_finales(netG, CONFIG[\"latent_dim\"], CONFIG[\"num_final_images\"], device, CONFIG[\"results_path\"])\n",
    "    \n",
    "    # --- Visualizar m√©tricas ---\n",
    "    visualizar_metricas(CONFIG[\"results_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc91fd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 10: FUNCI√ìN PRINCIPAL\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal que ejecuta todo el pipeline de la GAN.\n",
    "    \"\"\"\n",
    "    print(\"üéØ GENERATIVE ADVERSARIAL NETWORK (GAN) PARA AUTOM√ìVILES\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Implementaci√≥n completa de DCGAN con PyTorch\")\n",
    "    print(\"Dataset: CIFAR-10 (filtrado para autom√≥viles)\")\n",
    "    print(\"Objetivo: Generar 30 im√°genes sint√©ticas de autom√≥viles\")\n",
    "    print(\"Versi√≥n: Google Colab Optimizada\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Configurar el proyecto\n",
    "    CONFIG = configurar_proyecto()\n",
    "    \n",
    "    # Ejecutar el entrenamiento\n",
    "    entrenar_gan(CONFIG)\n",
    "    \n",
    "    print(\"\\nüéâ ¬°Proceso completado exitosamente!\")\n",
    "    print(f\"üìÅ Revisa la carpeta '{CONFIG['results_path']}' para ver las im√°genes generadas.\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"üí° Para descargar las im√°genes, usa el panel de archivos de Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc050ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EJECUCI√ìN DEL SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
